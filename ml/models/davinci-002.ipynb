{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset\n",
    "\n",
    "Dealing with list format, as shown above, might be convenient for small datasets. However, there are several benefits to saving the data in JSONL (JSON Lines) format. The benefits include scalability, interoperability, simplicity, and also compatibility with OpenAI API, which requires data in JSONL format when creating fine-tuning jobs.\n",
    "\n",
    "The following code leverages the helper function prepare_data to create both the training and validation data in JSONL formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = \"../data/training_data.jsonl\"\n",
    "validation_file_name = \"../data/validation_data.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training File ID: FileObject(id='file-FXoXZ53jIk0sPaWfZE5YtfEs', bytes=68382, created_at=1711304270, filename='training_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Validation File ID: FileObject(id='file-PqQMxVxhp200wEn3DopMbwA0', bytes=3588, created_at=1711304270, filename='validation_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "training_file_id = client.files.create(\n",
    "  file=open(training_file_name, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "validation_file_id = client.files.create(\n",
    "  file=open(validation_file_name, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(f\"Training File ID: {training_file_id}\")\n",
    "print(f\"Validation File ID: {validation_file_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fine-tuning job\n",
    "\n",
    "This fine-tuning process is highly inspired by the openai-cookbook performing fine-tuning on Microsoft Azure.\n",
    "\n",
    "To perform the fine-tuning we will use the following two steps: (1) define hyperparameters, and (2) trigger the fine-tuning.\n",
    "\n",
    "We will fine-tune the davinci model and run it for 15 epochs using a batch size of 3 and a learning rate multiplier of 0.3 using the training and validation datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successful execution of the previous code displays below the unique identifier of the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tunning model with jobID: ftjob-GBZKnYVioaSskTTZYXPwDYY8.\n",
      "Training Response: FineTuningJob(id='ftjob-GBZKnYVioaSskTTZYXPwDYY8', created_at=1711304271, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=15, batch_size=3, learning_rate_multiplier=0.3), model='davinci-002', object='fine_tuning.job', organization_id='org-wkUFLlJRyOXDuAkBFUtPtrii', result_files=[], status='validating_files', trained_tokens=None, training_file='file-FXoXZ53jIk0sPaWfZE5YtfEs', validation_file='file-PqQMxVxhp200wEn3DopMbwA0', user_provided_suffix=None)\n",
      "Training Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file_id.id, \n",
    "  validation_file=validation_file_id.id,\n",
    "  model=\"davinci-002\", \n",
    "  hyperparameters={\n",
    "    \"n_epochs\": 15,\n",
    "\t\"batch_size\": 3,\n",
    "\t\"learning_rate_multiplier\": 0.3\n",
    "  }\n",
    ")\n",
    "job_id = response.id\n",
    "status = response.status\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above generates the following information for the jobID (`ftjob-SqZvz9Rpjn2nSxtsn8ozMJu4`), the training response, and the training status (pending)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pending status does not provide any relevant information. However, we can have more insight into the training process by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming events for the fine-tuning job: ftjob-GBZKnYVioaSskTTZYXPwDYY8\n",
      "2024-03-24 14:17:51 Validating training file: file-FXoXZ53jIk0sPaWfZE5YtfEs and validation file: file-PqQMxVxhp200wEn3DopMbwA0\n",
      "2024-03-24 14:17:51 Created fine-tuning job: ftjob-GBZKnYVioaSskTTZYXPwDYY8\n"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "import datetime\n",
    "\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "    status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "    print(f\"Stream interrupted. Job is still {status}.\")\n",
    "    return\n",
    "\n",
    "\n",
    "print(f\"Streaming events for the fine-tuning job: {job_id}\")\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\n",
    "try:\n",
    "    for event in events:\n",
    "        print(\n",
    "            f'{datetime.datetime.fromtimestamp(event.created_at)} {event.message}'\n",
    "        )\n",
    "except Exception:\n",
    "    print(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the fine-tuning job status\n",
    "\n",
    "Let's verify that our operation was successful, and additionally, we can examine all the fine-tuning operations by using a list operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job not in terminal status: validating_files. Waiting.\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: succeeded\n",
      "Checking other finetune jobs in the subscription.\n",
      "Found 7 finetune jobs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "    print(f\"Job not in terminal status: {status}. Waiting.\")\n",
    "    while status not in [\"succeeded\", \"failed\"]:\n",
    "        time.sleep(2)\n",
    "        status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "        print(f\"Status: {status}\")\n",
    "else:\n",
    "    print(f\"Finetune job {job_id} finished with status: {status}\")\n",
    "print(\"Checking other finetune jobs in the subscription.\")\n",
    "result = client.fine_tuning.jobs.list()\n",
    "print(f\"Found {len(result.data)} finetune jobs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of the model\n",
    "\n",
    "Finally, the fine-tuned model can be retrieved from the “fine_tuned_model” attribute. The following print statement shows that the name of the final mode is: `ft:davinci-002:personal::8gKnyxn3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:davinci-002:personal::96MoK63t\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the finetuned model\n",
    "fine_tuned_model = result.data[0].fine_tuned_model\n",
    "print(fine_tuned_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model, we can run queries to validate its results by providing a prompt, the model name, and creating a query with the openai.Completion.create() function. The result is retrieved from the answer dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " studying in the United States. As a nonresident student living in the United States\n",
      "! Through our Student Line of Credit you can flex your financial potential! Encourage\n"
     ]
    }
   ],
   "source": [
    "new_prompt = \"Create a website marketing campaign for a Checking Account aimed at International Students\"\n",
    "answer = client.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt\n",
    ")\n",
    "\n",
    "print(answer.choices[0].text)\n",
    "\n",
    "new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "answer = client.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  prompt=new_prompt\n",
    ")\n",
    "\n",
    "print(answer.choices[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
