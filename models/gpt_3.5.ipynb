{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset\n",
    "\n",
    "Dealing with list format, as shown above, might be convenient for small datasets. However, there are several benefits to saving the data in JSONL (JSON Lines) format. The benefits include scalability, interoperability, simplicity, and also compatibility with OpenAI API, which requires data in JSONL format when creating fine-tuning jobs.\n",
    "\n",
    "The following code leverages the helper function prepare_data to create both the training and validation data in JSONL formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the path to the original dataset\n",
    "file_path = '../data/final_data/final_finetuning.jsonl'\n",
    "\n",
    "# Load the data, handling possible malformed JSON\n",
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            json_obj = json.loads(line)\n",
    "            data.append(json_obj)\n",
    "        except json.JSONDecodeError:\n",
    "            # Handle or log the malformed line if needed\n",
    "            pass\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define file paths for the training and test data\n",
    "train_file_path = '../data/final_data/final_finetuning_train.jsonl'\n",
    "test_file_path = '../data/final_data/final_finetuning_test.jsonl'\n",
    "\n",
    "# Save the training set\n",
    "with open(train_file_path, 'w') as train_file:\n",
    "    for item in train_data:\n",
    "        train_file.write(json.dumps(item) + '\\n')\n",
    "\n",
    "# Save the test set\n",
    "with open(test_file_path, 'w') as test_file:\n",
    "    for item in test_data:\n",
    "        test_file.write(json.dumps(item) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Invalid file format. Line 3, message 4: No match for discriminator 'role' and value 'email' (allowed values: 'assistant', 'function', 'system', 'user')\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m training_file_id \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      2\u001b[0m   file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mopen\u001b[39m(train_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      3\u001b[0m   purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine-tune\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m test_file_id \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43mpurpose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfine-tune\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining File ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_file_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest File ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_file_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ProjectsinML/GitHub/Personalized-content-generation-for-Finance-Industry/.venv/lib/python3.11/site-packages/openai/resources/files.py:107\u001b[0m, in \u001b[0;36mFiles.create\u001b[0;34m(self, file, purpose, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m files:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# It should be noted that the actual Content-Type header that will be\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# sent to the server will contain a `boundary` parameter, e.g.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# multipart/form-data; boundary=---abc--\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultipart/form-data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFileObject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ProjectsinML/GitHub/Personalized-content-generation-for-Finance-Industry/.venv/lib/python3.11/site-packages/openai/_base_client.py:1208\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1196\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1204\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1205\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1206\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1207\u001b[0m     )\n\u001b[0;32m-> 1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/ProjectsinML/GitHub/Personalized-content-generation-for-Finance-Industry/.venv/lib/python3.11/site-packages/openai/_base_client.py:897\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    890\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    896\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ProjectsinML/GitHub/Personalized-content-generation-for-Finance-Industry/.venv/lib/python3.11/site-packages/openai/_base_client.py:988\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    985\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    987\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    991\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    992\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    995\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    996\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid file format. Line 3, message 4: No match for discriminator 'role' and value 'email' (allowed values: 'assistant', 'function', 'system', 'user')\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "training_file_id = client.files.create(\n",
    "  file=open(train_file_path, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "test_file_id = client.files.create(\n",
    "  file=open(test_file_path, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(f\"Training File ID: {training_file_id}\")\n",
    "print(f\"Test File ID: {test_file_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fine-tuning job\n",
    "\n",
    "This fine-tuning process is highly inspired by the openai-cookbook performing fine-tuning on Microsoft Azure.\n",
    "\n",
    "To perform the fine-tuning we will use the following two steps: (1) define hyperparameters, and (2) trigger the fine-tuning.\n",
    "\n",
    "We will fine-tune the davinci model and run it for 15 epochs using a batch size of 3 and a learning rate multiplier of 0.3 using the training and validation datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successful execution of the previous code displays below the unique identifier of the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tunning model with jobID: ftjob-Cz9oUrArJEJnGLAtijUdGOoX.\n",
      "Training Response: FineTuningJob(id='ftjob-Cz9oUrArJEJnGLAtijUdGOoX', created_at=1711658631, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=15, batch_size=3, learning_rate_multiplier=0.3), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-wkUFLlJRyOXDuAkBFUtPtrii', result_files=[], status='validating_files', trained_tokens=None, training_file='file-N59UqF5TuZwPnrj1kVfkbgqI', validation_file='file-zPH1ujZjm1QNWUoyug6Ws8zW', user_provided_suffix=None)\n",
      "Training Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file_id.id, \n",
    "  validation_file=validation_file_id.id,\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  hyperparameters={\n",
    "    \"n_epochs\": 15,\n",
    "\t\"batch_size\": 3,\n",
    "\t\"learning_rate_multiplier\": 0.3\n",
    "  }\n",
    ")\n",
    "job_id = response.id\n",
    "status = response.status\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above generates the following information for the jobID (`ftjob-SqZvz9Rpjn2nSxtsn8ozMJu4`), the training response, and the training status (pending)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pending status does not provide any relevant information. However, we can have more insight into the training process by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming events for the fine-tuning job: ftjob-Cz9oUrArJEJnGLAtijUdGOoX\n",
      "2024-03-28 16:43:51 Validating training file: file-N59UqF5TuZwPnrj1kVfkbgqI and validation file: file-zPH1ujZjm1QNWUoyug6Ws8zW\n",
      "2024-03-28 16:43:51 Created fine-tuning job: ftjob-Cz9oUrArJEJnGLAtijUdGOoX\n"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "import datetime\n",
    "\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "    status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "    print(f\"Stream interrupted. Job is still {status}.\")\n",
    "    return\n",
    "\n",
    "\n",
    "print(f\"Streaming events for the fine-tuning job: {job_id}\")\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\n",
    "try:\n",
    "    for event in events:\n",
    "        print(\n",
    "            f'{datetime.datetime.fromtimestamp(event.created_at)} {event.message}'\n",
    "        )\n",
    "except Exception:\n",
    "    print(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the fine-tuning job status\n",
    "\n",
    "Let's verify that our operation was successful, and additionally, we can examine all the fine-tuning operations by using a list operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job not in terminal status: validating_files. Waiting.\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: succeeded\n",
      "Checking other finetune jobs in the subscription.\n",
      "Found 11 finetune jobs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "    print(f\"Job not in terminal status: {status}. Waiting.\")\n",
    "    while status not in [\"succeeded\", \"failed\"]:\n",
    "        time.sleep(2)\n",
    "        status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "        print(f\"Status: {status}\")\n",
    "else:\n",
    "    print(f\"Finetune job {job_id} finished with status: {status}\")\n",
    "print(\"Checking other finetune jobs in the subscription.\")\n",
    "result = client.fine_tuning.jobs.list()\n",
    "print(f\"Found {len(result.data)} finetune jobs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of the model\n",
    "\n",
    "Finally, the fine-tuned model can be retrieved from the “fine_tuned_model” attribute. The following print statement shows that the name of the final mode is: `ft:davinci-002:personal::8gKnyxn3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0125:personal::97qznw0E\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the finetuned model\n",
    "fine_tuned_model = result.data[0].fine_tuned_model\n",
    "print(fine_tuned_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model, we can run queries to validate its results by providing a prompt, the model name, and creating a query with the openai.Completion.create() function. The result is retrieved from the answer dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Welcome to our leading financial institution, where your financial journey starts with assurance and growth. Explore our New Beginnings Savings Account, tailored exclusively for permanent residents like you. This account offers more than just a place to keep your savings; it represents a value and growth-driven financial relationship you can trust.\\n\\n**New Beginnings Savings Account for Permanent Residents at a Glance:**\\n\\n**High-Yield Interest Rates:** Enjoy a competitive interest rate that grows your savings effectively and aligns with your aspirations.\\n\\n**No Monthly Maintenance Fee:** We value your progress towards reaching your financial goals — that's why there are no monthly maintenance fees associated with the account.\\n\\n**Easy Access and Online Personal Banking:** Access your account information, move money, deposit checks, and view transaction history with our online and mobile banking services. Experience seamless banking, tailored to meet your needs, wherever you are.\\n\\n**Priority Service and Special Offers:** Count on premium customer service from a dedicated team that understands your unique needs as a permanent resident. Benefit from exclusive offers and rates to boost your savings.\\n\\n**Feel confident in your financial future. Your journey matters, and we're here to help you prosper and grow sustainably. Welcome to New Beginnings Savings Account — start your financial success with us.**\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"Develop comprehensive website content for our New Beginnings Savings Account, specifically designed for permanent residents.\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)\n",
    "\n",
    "# new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "# answer = client.completions.create(\n",
    "#   model=fine_tuned_model,\n",
    "#   prompt=new_prompt\n",
    "# )\n",
    "\n",
    "# print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Explore perpetual benefits with our Savings Account, tailored for long-term residents. With competitive interest rates, seamless online access, and zero monthly fees, your funds will flourish effortlessly. Enjoy peace of mind with free global transfers and industry-leading security. Extend your savings with adjustable terms and automatic deposits. Our intuitive mobile app means financial freedom is always within reach. Join a bank that knows the value of permanency, providing lifetime support and loyalty rewards. Your future deserves stability. Your savings deserve growth. Partner with us and build a foundation for a prosperous life here, now, and forever.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"Develop comprehensive website content for our Savings Account in 100 words, specifically designed for permanent residents.\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)\n",
    "\n",
    "# new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "# answer = client.completions.create(\n",
    "#   model=fine_tuned_model,\n",
    "#   prompt=new_prompt\n",
    "# )\n",
    "\n",
    "# print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='🏡 Are you a permanent resident looking to put down roots in the land of opportunity? Let us help you unlock the door to your dream home! 🌟\\n\\n🛠️ Our innovative mortgages are tailor-made for permanent residents, making the process smoother and more rewarding. We understand the nuances that come with your residency status and are here to guide you every step of the way!\\n\\n🔑 Dive into our exclusive range of mortgage packages, each one as unique as the American Dream itself. From low down payments to attractive interest rates, we\\'ve got you covered. Our dedicated team will ensure that you secure a mortgage that not only fits your financial situation but also aligns with your long-term goals.\\n\\n🏋️\\u200d♀️ Worried about credit history? Don\\'t be! We specialize in working with residents building their credit scores in the U.S. Lenders that understand your journey are here walking by your side.\\n\\n📈 Plus, with our renowned online application process, getting closer to your new home is just a click away. Let\\'s make paperwork a thing of the past together!\\n\\n🌺 Find financial tranquility with a mortgage that supports your vision. Let us be your bridge to that front door where \"Welcome Home\" is more than an inscription – it\\'s an invitation to the future. Invest today in the place where permanence and prosperity meet.\\n\\n📲 Reach out and take the first step towards securing your forever home today! #MortgagesForDreams #SecureYourFuture #PermanentResidentMortgages', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"create detailed social media content for mortage seekers in 300 words, specifically designed for permanent residents.\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)\n",
    "\n",
    "# new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "# answer = client.completions.create(\n",
    "#   model=fine_tuned_model,\n",
    "#   prompt=new_prompt\n",
    "# )\n",
    "\n",
    "# print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Are you looking to put down roots and establish your own piece of paradise in a new country? Unlock the door to your next chapter as a permanent resident with our hassle-free mortgage solutions! Our experienced team understands the unique needs of newcomers and is here to guide you every step of the way. From pre-approval to unlocking the front door of your dream home, we have you covered. As a permanent resident, your future is bright, and we're excited to be part of that journey. Welcome home! #MortgageAdventures #PermanentResidentLife\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"create detailed social media content for mortage seekers, specifically designed for permanent residents.\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)\n",
    "\n",
    "# new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "# answer = client.completions.create(\n",
    "#   model=fine_tuned_model,\n",
    "#   prompt=new_prompt\n",
    "# )\n",
    "\n",
    "# print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"🏡🔍 Looking to purchase your dream home in the U.S.? Our mortgage solutions are tailored for permanent residents with low rates, minimal down payments, and competitive terms to help you achieve homeownership. Say goodbye to sky-high rents and invest in your future starting today. Whether you're new to the mortgage process or seeking to refinance, our expert team understands the unique needs of permanent residents and will guide you every step of the way. Why let citizenship status hold you back from living the American Dream? DM us to learn more about our exclusive offers and eligibility requirements - your new home might be more within reach than you think. Come home to stability, security, and the pride of owning where your heart is. Housing stability - a step closer to citizenship and community integration. Let's make this journey together. 🇺🇸❤️ #MortgagesForResidents #DreamHome #PermanentResidency #MortgageSolutions\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"create detailed social media content for mortage seekers in 200 words, specifically designed for permanent residents.\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)\n",
    "\n",
    "# new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "# answer = client.completions.create(\n",
    "#   model=fine_tuned_model,\n",
    "#   prompt=new_prompt\n",
    "# )\n",
    "\n",
    "# print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      2\u001b[0m   model\u001b[38;5;241m=\u001b[39mfine_tuned_model,\n\u001b[1;32m      3\u001b[0m   messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a parameter-based prompt for creating marketing materials\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      5\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a website marketing campaign for a Checking Account aimed at International Students in 5 lines\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      6\u001b[0m   ]\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"Create a website marketing campaign for a Checking Account aimed at International Students in 5 lines\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
