{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset\n",
    "\n",
    "Dealing with list format, as shown above, might be convenient for small datasets. However, there are several benefits to saving the data in JSONL (JSON Lines) format. The benefits include scalability, interoperability, simplicity, and also compatibility with OpenAI API, which requires data in JSONL format when creating fine-tuning jobs.\n",
    "\n",
    "The following code leverages the helper function prepare_data to create both the training and validation data in JSONL formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the path to the original dataset\n",
    "file_path = '../data/final_data/final_finetuning.jsonl'\n",
    "\n",
    "# Load the data, handling possible malformed JSON\n",
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            json_obj = json.loads(line)\n",
    "            data.append(json_obj)\n",
    "        except json.JSONDecodeError:\n",
    "            # Handle or log the malformed line if needed\n",
    "            pass\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define file paths for the training and test data\n",
    "train_file_path = '../data/final_data/final_finetuning_train.jsonl'\n",
    "test_file_path = '../data/final_data/final_finetuning_test.jsonl'\n",
    "\n",
    "# Save the training set\n",
    "with open(train_file_path, 'w') as train_file:\n",
    "    for item in train_data:\n",
    "        train_file.write(json.dumps(item) + '\\n')\n",
    "\n",
    "# Save the test set\n",
    "with open(test_file_path, 'w') as test_file:\n",
    "    for item in test_data:\n",
    "        test_file.write(json.dumps(item) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training File ID: FileObject(id='file-2Hu9XBBlZrL7gYm8tTyhrjFy', bytes=79696, created_at=1711984006, filename='final_finetuning_train.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Test File ID: FileObject(id='file-hJJahvMXeOKVNfqFOpHx76RN', bytes=19223, created_at=1711984007, filename='final_finetuning_test.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "training_file_id = client.files.create(\n",
    "  file=open(train_file_path, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "test_file_id = client.files.create(\n",
    "  file=open(test_file_path, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(f\"Training File ID: {training_file_id}\")\n",
    "print(f\"Test File ID: {test_file_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a fine-tuning job\n",
    "\n",
    "This fine-tuning process is highly inspired by the openai-cookbook performing fine-tuning on Microsoft Azure.\n",
    "\n",
    "To perform the fine-tuning we will use the following two steps: (1) define hyperparameters, and (2) trigger the fine-tuning.\n",
    "\n",
    "We will fine-tune the davinci model and run it for 15 epochs using a batch size of 3 and a learning rate multiplier of 0.3 using the training and validation datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successful execution of the previous code displays below the unique identifier of the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tunning model with jobID: ftjob-eLHKJZBbs4V1VMPgHUlfUISj.\n",
      "Training Response: FineTuningJob(id='ftjob-eLHKJZBbs4V1VMPgHUlfUISj', created_at=1711984008, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=15, batch_size=3, learning_rate_multiplier=0.3), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-wkUFLlJRyOXDuAkBFUtPtrii', result_files=[], status='validating_files', trained_tokens=None, training_file='file-2Hu9XBBlZrL7gYm8tTyhrjFy', validation_file='file-hJJahvMXeOKVNfqFOpHx76RN', user_provided_suffix=None)\n",
      "Training Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file_id.id, \n",
    "  validation_file=test_file_id.id,\n",
    "  model=\"gpt-3.5-turbo\", \n",
    "  hyperparameters={\n",
    "    \"n_epochs\": 15,\n",
    "\t\"batch_size\": 3,\n",
    "\t\"learning_rate_multiplier\": 0.3\n",
    "  }\n",
    ")\n",
    "job_id = response.id\n",
    "status = response.status\n",
    "\n",
    "print(f'Fine-tunning model with jobID: {job_id}.')\n",
    "print(f\"Training Response: {response}\")\n",
    "print(f\"Training Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above generates the following information for the jobID (`ftjob-SqZvz9Rpjn2nSxtsn8ozMJu4`), the training response, and the training status (pending)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pending status does not provide any relevant information. However, we can have more insight into the training process by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming events for the fine-tuning job: ftjob-eLHKJZBbs4V1VMPgHUlfUISj\n",
      "2024-04-01 11:06:48 Validating training file: file-2Hu9XBBlZrL7gYm8tTyhrjFy and validation file: file-hJJahvMXeOKVNfqFOpHx76RN\n",
      "2024-04-01 11:06:48 Created fine-tuning job: ftjob-eLHKJZBbs4V1VMPgHUlfUISj\n"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "import datetime\n",
    "\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "    status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "    print(f\"Stream interrupted. Job is still {status}.\")\n",
    "    return\n",
    "\n",
    "\n",
    "print(f\"Streaming events for the fine-tuning job: {job_id}\")\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id)\n",
    "try:\n",
    "    for event in events:\n",
    "        print(\n",
    "            f'{datetime.datetime.fromtimestamp(event.created_at)} {event.message}'\n",
    "        )\n",
    "except Exception:\n",
    "    print(\"Stream interrupted (client disconnected).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the fine-tuning job status\n",
    "\n",
    "Let's verify that our operation was successful, and additionally, we can examine all the fine-tuning operations by using a list operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job not in terminal status: validating_files. Waiting.\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: validating_files\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: running\n",
      "Status: succeeded\n",
      "Checking other finetune jobs in the subscription.\n",
      "Found 13 finetune jobs.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "    print(f\"Job not in terminal status: {status}. Waiting.\")\n",
    "    while status not in [\"succeeded\", \"failed\"]:\n",
    "        time.sleep(2)\n",
    "        status = client.fine_tuning.jobs.retrieve(job_id).status\n",
    "        print(f\"Status: {status}\")\n",
    "else:\n",
    "    print(f\"Finetune job {job_id} finished with status: {status}\")\n",
    "print(\"Checking other finetune jobs in the subscription.\")\n",
    "result = client.fine_tuning.jobs.list()\n",
    "print(f\"Found {len(result.data)} finetune jobs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of the model\n",
    "\n",
    "Finally, the fine-tuned model can be retrieved from the ‚Äúfine_tuned_model‚Äù attribute. The following print statement shows that the name of the final mode is: `ft:davinci-002:personal::8gKnyxn3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0125:personal::99Du0H0D\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the finetuned model\n",
    "fine_tuned_model = result.data[0].fine_tuned_model\n",
    "print(fine_tuned_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model, we can run queries to validate its results by providing a prompt, the model name, and creating a query with the openai.Completion.create() function. The result is retrieved from the answer dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Welcome to a life of new beginnings and limitless opportunities! Elevate your savings journey with our exclusive New Beginnings Savings Account, tailored for permanent residents seeking a financial partner that understands their unique aspirations. Designed to be more than just a bank account, it‚Äôs your gateway to a wealth of benefits and a trusted ally in realizing your dreams. Say hello to a future where your money grows with purpose and your goals are nurtured with care.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"Develop comprehensive website content for our New Beginnings Savings Account, specifically designed for permanent residents.\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)\n",
    "\n",
    "# new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "# answer = client.completions.create(\n",
    "#   model=fine_tuned_model,\n",
    "#   prompt=new_prompt\n",
    "# )\n",
    "\n",
    "# print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Discover financial stability with our Savings Account, exclusively tailored for permanent residents. Enjoy competitive interest rates, zero monthly fees, and bonus interest every month for three years. Dive into a world of convenience with unlimited free transactions, mobile banking, and quick interbank transfers. Grow your wealth effortlessly, with the ability to easily access your money whenever you need it. Start your journey towards financial success with a bank that understands the importance of long-term planning for permanent residents in Canada. Welcome to a future where your savings thrive with every deposit.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"Develop comprehensive website content for our Savings Account in 100 words, specifically designed for permanent residents.\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)\n",
    "\n",
    "# new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "# answer = client.completions.create(\n",
    "#   model=fine_tuned_model,\n",
    "#   prompt=new_prompt\n",
    "# )\n",
    "\n",
    "# print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Calling all permanent residents! üá®üá¶ Dreaming of a place to call your very own? Say 'hello' to your dream home with our mortgage solutions tailored just for you. Our team doesn't just open doors; we're here to hand you the keys to your future. Why wait any longer when you're this close to making memories in your forever home? True for today, true for life. Partner with us and turn your dream house into your reality. We offer more than mortgages; we provide a pathway to financial confidence and independence. With our expert guidance, purchasing your home isn't just a process ‚Äì it's an exciting journey. By choosing us, you're choosing more than just a financial institution; you're choosing a partner with a deep understanding of what home means to you. Our commitment doesn't end with great rates; we're here for you at every step, offering advice, answering questions, and making your journey to homeownership as smooth as possible. Let us handle the numbers, so you can focus on picturing your new life within those walls you'll soon call 'Home Sweet Home.' Ready to unlock the doors to the next chapter of your life story? Let's do this together. #StepIntoYourHome sweet home with [Your Mortgage Company].#PermissionToDreamGranted #NavigatingHomeOwnership #SeizeYourKeyWithUs\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"create detailed social media content for mortage seekers in 300 words, specifically designed for permanent residents.\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)\n",
    "\n",
    "# new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "# answer = client.completions.create(\n",
    "#   model=fine_tuned_model,\n",
    "#   prompt=new_prompt\n",
    "# )\n",
    "\n",
    "# print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Are you seeking your dream home as a Permanent Resident? üè° In Canada, your dreams deserve a solid foundation, and we're here to help. With tailored mortgage solutions, we're dedicated to turning your goals into front-door keys. Our team understands the aspirations of Permanent Residents and collaborates with you to secure your place among the pines and maples. Let's build a future you‚Äôre proud to call home. üåü #MortgageMagic #PermanentlyYours\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"create detailed social media content for mortage seekers, specifically designed for permanent residents.\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)\n",
    "\n",
    "# new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "# answer = client.completions.create(\n",
    "#   model=fine_tuned_model,\n",
    "#   prompt=new_prompt\n",
    "# )\n",
    "\n",
    "# print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Unlock home ownership with tailored mortgage solutions. Secure a place to call your own, build equity, and invest in your future while laying down roots in Canada. Our expert advisors, well-versed in the financial nuances that come with permanent residency, craft personalized strategies to turn your property dreams into tangible assets. We understand the unique challenges and opportunities permanent residents face on their path to homeownership and offer guidance every step of the way. Benefit from competitive rates, flexible terms, and transparent processes built on trust. Your home-buying journey begins here, with a partner that prioritizes your goals and values. Let's navigate the mortgage landscape together, ensuring that each decision aligns with your long-term aspirations. It's not just about buying a house; it's about creating a foundation for your future. Time to lay down roots and watch your investments grow alongside your family. The key to a thriving financial future starts with a stable home base ‚Äì and we're here to make that a reality.\\n\\n\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"create detailed social media content for mortage seekers in 200 words, specifically designed for permanent residents.\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)\n",
    "\n",
    "# new_prompt = \"Design an email for the TD Student Line of Credit, aimed at students seeking flexible funding solutions for their academic journey\"\n",
    "# answer = client.completions.create(\n",
    "#   model=fine_tuned_model,\n",
    "#   prompt=new_prompt\n",
    "# )\n",
    "\n",
    "# print(answer.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Discover the perfect companion for your studies abroad with our International Student Checking Account - where global convenience meets essential financial tools! Get a head start with no monthly fees, unlimited interbank transfers, and waived ATM withdrawal fees worldwide. Seamlessly manage your money through our user-friendly mobile app and track expenses with real-time alerts. Open your account in minutes online and enjoy exclusive benefits designed to grow with you on your academic journey. Stay connected globally with dedicated customer support and valuable resources tailored to your needs. Ready to make the most of your international experience?', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "answer = client.chat.completions.create(\n",
    "  model=fine_tuned_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"This is a parameter-based prompt for creating marketing materials\"},\n",
    "    {\"role\": \"user\", \"content\": \"Create a website marketing campaign for a Checking Account aimed at International Students in 5 lines\"}\n",
    "  ]\n",
    ")\n",
    "print(answer.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
